{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# remove headers, footers, and quotes of other posts, to prevent overfitting on unhelpful features\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=2, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Something about how Koresh had threatened to cause local \\nproblems with all these wepaons he had and was alleged to\\nhave.  \\n\\nSomeone else will post more details soon, I'm sure.\\n\\nOther News:\\nSniper injures 9 outside MCA buildling in L.A.  Man arrested--suspect\\nwas disgruntled employee of Universal Studios, which\\nis a division of M.C.A.\\n\\n\\nQUESTION:\\nWhat will Californians do with all those guns after the Reginald\\ndenny trial?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents, 1336 word featuers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_df=0.8, min_df=100, stop_words='english')\n",
    "X = cv.fit_transform(documents)\n",
    "feature_names = cv.get_feature_names()\n",
    "print(\"{} documents, {} word featuers.\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA.\n",
      "Finished.\n",
      "22.96079111099243 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time\n",
    "\n",
    "no_topics = 20\n",
    "\n",
    "# n_components: number of topics\n",
    "# max_iter: the number of times to iterate through the corpus to update the model\n",
    "# learning_method: online, partition the training for faster training on larger datasets\n",
    "# learning_offset: the higher this is, the less weight on earlier training batches to reduce its influence\n",
    "# random_state: for reproducibility\n",
    "# verbose: set to 1 or 2 for updates to be printed during training\n",
    "# n_jobs: number of CPUs to use for parallelization\n",
    "\n",
    "print(\"Training LDA.\")\n",
    "st = time.time()\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=no_topics, \n",
    "    max_iter=5, \n",
    "    learning_method='online', \n",
    "    learning_offset=50, \n",
    "    random_state=0,\n",
    "    n_jobs=4)\n",
    "lda.fit(X)\n",
    "print(\"Finished.\")\n",
    "print(\"{} seconds.\".format(time.time() - st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the learned model\n",
    "\n",
    "The model learned by LDA consists of a _term-topic distribution_, which tells us the probability of emitting a word, given a topic. This distribution can be obtained as a matrix from the learned model, with n_component rows (representing each \"topic\") and d columns, where d is the number of word features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1336)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the probability of a certain word in a certain topic, find the value at the topic's row and the word's column. \n",
    "\n",
    "The best way to \"get to know\" the discovered topics is to look at the words with the highest probability per topic. \n",
    "\n",
    "Here's a function that can easily extract that info for us. In order to know which word corresponds to which column, we need to pull in the feature names from the vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic {}:\".format(topic_idx))\n",
    "        # arrange indexes of topic ascending order\n",
    "        # get the indexes of the last no_top_words in the arranged vector\n",
    "        # reverse them (so biggest is first)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words-1:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "government president car people health cars congress house federal use\n",
      "Topic 1:\n",
      "mr does question true point evidence right answer say argument\n",
      "Topic 2:\n",
      "00 new price sale offer shipping condition 250 san sell\n",
      "Topic 3:\n",
      "edu server graphics cs mit uk com memory comp ac\n",
      "Topic 4:\n",
      "god jesus people bible christian life church christians does faith\n",
      "Topic 5:\n",
      "10 15 14 11 12 25 20 17 16 18\n",
      "Topic 6:\n",
      "jews war 000 people women children killed years men military\n",
      "Topic 7:\n",
      "software mac version pc user color using available sun image\n",
      "Topic 8:\n",
      "don just think like know good ve going time really\n",
      "Topic 9:\n",
      "state states israel public rights law new people israeli united\n",
      "Topic 10:\n",
      "space university internet nasa research information available anonymous ftp 1993\n",
      "Topic 11:\n",
      "game team year play games season hockey players league win\n",
      "Topic 12:\n",
      "problem time window use power speed work using like just\n",
      "Topic 13:\n",
      "said gun went people didn told guns says day time\n",
      "Topic 14:\n",
      "thanks com mail know does help send list like email\n",
      "Topic 15:\n",
      "book read value rules article title define michael double author\n",
      "Topic 16:\n",
      "file windows drive files dos program card disk use scsi\n",
      "Topic 17:\n",
      "key chip encryption keys clipper security use government public law\n",
      "Topic 18:\n",
      "believe don people hell make claim world knowledge know way\n",
      "Topic 19:\n",
      "data output use used bit input tape high device cost\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of these topics are pretty coherent. Topic 0 is government, Topic 1 is debate, Topic 2 is sales, and so forth. There seem to be some unsavory topics as well; at any rate, LDA has helped \"distil\" the semantic content of this large text set and let us get an overview of what's \"in\" the corpus.\n",
    "\n",
    "# Document-topic distribution\n",
    "\n",
    "We can also use a trained LDA model to take in a document and tell us what its estimate of the distribution of topics for that document is. Here is document 1. We can see it's technical, about computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have an Okidata 2410 printer for which I would like to have a printer driver.\\nHas anyone seen such a thing?  There is not one on the Microsoft BBS.\\nI can print to it from Windows but I have no fonts available and with\\nParadox for Windows I can't print labels on it unless there is a proper printer\\ndefined.\\n\\n\\nThanks,\\n\\nBryan K. Ward\\nSurvey Research Center\\nUniversity of Utah\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the vector representation of this document, and feed it to the LDA model to see its corresponding topic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00263158, 0.00263158, 0.00263158, 0.00263158, 0.00263158,\n",
       "        0.00263158, 0.00263158, 0.34075273, 0.23512517, 0.00263158,\n",
       "        0.18215102, 0.00263158, 0.00263158, 0.00263158, 0.00263158,\n",
       "        0.00263158, 0.19986582, 0.00263158, 0.00263158, 0.00263158]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = X[1, :]\n",
    "d1_topics = lda.transform(d1)\n",
    "d1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  8, 16, 10, 14, 18, 12, 19,  9, 17,  1,  4, 13,  6, 11,  5,  0,\n",
       "        3,  2, 15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(d1_topics)[0][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model says this document is 34% topic 7, 23% topic 8, and 16% topic 16.  Topic 7 and 16 are indeed computer-related topics. Topic 8 is a less coherent topic that seems to be storing \"filler\" words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending a re-representation to a machine learning algorithm\n",
    "\n",
    "LDA can be conceptualizing as \"summarizing\" data. Instead of representing each document as a count vector with 1336 features, we can respresent it as a vector of 20 topic proportions. On one hand, information is lost in this re-representation, but on the other hand, there is potential that this \"summarization\" makes patterns easier for machine learning classifiers to grasp. \n",
    "\n",
    "Each document in this dataset belongs to one of 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 600),\n",
       " (15, 599),\n",
       " (8, 598),\n",
       " (9, 597),\n",
       " (11, 595),\n",
       " (7, 594),\n",
       " (13, 594),\n",
       " (5, 593),\n",
       " (14, 593),\n",
       " (2, 591),\n",
       " (12, 591),\n",
       " (3, 590),\n",
       " (6, 585),\n",
       " (1, 584),\n",
       " (4, 578),\n",
       " (17, 564),\n",
       " (16, 546),\n",
       " (0, 480),\n",
       " (18, 465),\n",
       " (19, 377)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(dataset.target).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels aren't evenly distributed but the most common label has a count of 600, so the baseline for this task is 600/11314."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0530316422131872"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "600/11314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's train from the count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48166151126822804"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Now let's try training it only on the topic vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_topic = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_topic, y, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3588157313300928"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that didn't improve our score. We can conclude in this scenario that *IF* our goal is to predict a post's category then a simple count of the words in a post are better than a 20-topic topic model for achieving this task. \n",
    "\n",
    "However, the topic model gave us a human-understandable \"glimpse\" into the semantics of the the dataset. And there are other scenarios where topic vectors may substitute or be appended to other kinds of information before being input into an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Notes\n",
    "\n",
    "1. The usual caveats for using machine learning apply. LDA is very sensitive to preprocessing and hyperparameters, and to tell the truth I tinkered with some settings to get the model we just saw now. These include the min_df, max_df, and the number of topics. Depending on the size of your data you may have to tweak the max_iter and online settings.\n",
    "2. Single tweets probably won't work well out of the box on Tweets. As you know now, LDA relies on word counts, and since tweets are so short, the counts of words are small and its harder to estimate a document-topic distribution for a tweet. \n",
    "3. However, this will work well if you have a reason to aggregate tweets. For example, if each datapoint is a concatenation of all of a user's tweets, and you have tweets for many users. You could apply LDA here, find topics in the texts, and for each user obtain a user-topic distribution showing how often a user writes in a topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
