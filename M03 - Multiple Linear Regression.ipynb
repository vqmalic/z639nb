{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we learned how to do Simple Linear Regression. It's called simple because there is only one independent variable and one dependent variable. There's absolutely nothing in principle that prevents us from using multiple independent variables. In this case, it's called Multiple Linear Regression, but it uses the same scikit-learn function. The function that Multiple Linear Regression is attempting to estimate looks like this:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + ... + \\beta_n x_n$$\n",
    "\n",
    "We simply have a new coefficient for each new feature in the independent variables. \n",
    "\n",
    "Let's create some synthetic data. There will be 4 independent variables. The dependent variable will be created as follows:\n",
    "\n",
    "$$ y = 10 + 0.5x_1 + (-0.7)x_2 + 12x_3 + (-4.2)x_4 + \\epsilon$$\n",
    "\n",
    "As usually, the $\\epsilon$ represents noise that we're adding to the data.\n",
    "\n",
    "First, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(9216) # setting a seed for consistent results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data\n",
    "\n",
    "Now, we'll make 1000 samples. The $x$'s themselves will be distributed normally according to some mean and standard deviation that I'm just making up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.random.normal(5, 10, 1000)\n",
    "x2 = np.random.normal(-2.45, 4, 1000)\n",
    "x3 = np.random.normal(57.8, 14, 1000)\n",
    "x4 = np.random.normal(31.4, 20, 1000)\n",
    "noise = np.random.normal(0, 10, 1000)\n",
    "\n",
    "y = 10 + 0.5*x1 - 0.7*x2 + 12*x3 - 4.2*x4 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``x`` variables are our independent variables. The model will attempt to learn from this data. ``y`` is our dependent variable. We know *how* it was made, but the model does not. \n",
    "\n",
    "Scikit learn ``fit`` functions expects that the dependent variable training data by packaged as an array of arrays. But right now, each of our ``x`` variables are in separate arrays. We need to merge them together somehow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x1, x2, x3, x4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new array, ``X``, has 4 arrays inside of it. Each array has a length of 1000. We can therefor consider this to be a matrix of size $4 \\times 1000$. Each row is one of the data features, each column is one of the samples. We can actually check the size of this array of arrays by using dot notation and seeing the value of its attribute ``shape``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, ``X`` is a $4 \\times 1000$ grid. \n",
    "\n",
    "Recall, however, that in both programming and the math of data mining the training data should be matrices of size $n \\times d$, that is, the number of samples by the number of features. Right now, ``X`` is backwards. We need to flip the rows and the columns. I'm going to do that using a numpy function called ``transpose``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.transpose(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``X`` is an array of arrays, but ``y`` is still an array of numbers. We'll use the ``reshape`` trick to turn it into an array of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 484.39763051,  347.86637141,  653.44863166,  275.12867872,\n",
       "        515.38212337])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 484.39763051],\n",
       "       [ 347.86637141],\n",
       "       [ 653.44863166],\n",
       "       [ 275.12867872],\n",
       "       [ 515.38212337]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making and Training the Model\n",
    "\n",
    "Now we're good to go. Let's make the regressor model. First, we call the factory method ``LinearRegression`` to initialize an empty, new regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the model by calling ``fit`` and providing it with the training data and the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 484.39763051]\n",
      " [ 347.86637141]\n",
      " [ 653.44863166]\n",
      " [ 275.12867872]\n",
      " [ 515.38212337]]\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! The coefficients are in the model, ``lr``. Let's take a look first at the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.82809212])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the rest of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.44653135,  -0.67876566,  11.98323056,  -4.21864062]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the function we used to synthesize the data was \n",
    "\n",
    "$$ y = 10 + 0.5x_1 + (-0.7)x_2 + 12x_3 + (-4.2)x_4 + \\epsilon$$\n",
    "\n",
    "We've looked at the trained models coefficients, and so we know the estimation it came up with is\n",
    "\n",
    "$$ y = 11.83 + 0.45x_1 + (-0.68)x_2 + 11.98x_3 + (-4.22) x_4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. As with Simple Regression, now that we have a model we can predict new ``y`` values for new, unseen data. Let's say I have observed 2 new instances. Each instance has 4 features, $x_1$ through $x_4$. I simply call the predict function, and the model tells me its estimates of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29.99222134],\n",
       "       [-56.8894352 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[1, 2, 3, 4], [-5, 4, 7, 35]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
